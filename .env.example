# =============================================================================
# AI RAG System Configuration
# =============================================================================
# Copy this file to .env and customize for your environment
# 
# Quick start:
#   cp .env.example .env
#   nano .env  # Edit your settings
#   docker compose up -d
#

# =============================================================================
# PROJECT SETTINGS
# =============================================================================

PROJECT_NAME=airag
ENVIRONMENT=development  # development, staging, production
QDRANT_COLLECTION=documents

# =============================================================================
# DUAL-LLM CONFIGURATION
# =============================================================================
# The orchestrator and worker can use the same or different models
# Orchestrator: Faster, lighter model for intent classification
# Worker: Larger, smarter model for answer generation

# Orchestrator LLM (intent classification, planning, validation)
ORCHESTRATOR_MODEL=qwen2.5:14b
ORCHESTRATOR_TEMPERATURE=0.3
ORCHESTRATOR_MAX_TOKENS=2000
ORCHESTRATOR_CONFIDENCE_THRESHOLD=0.7
ORCHESTRATOR_MAX_RETRIES=2

# Worker LLM (RAG execution, answer generation)
WORKER_MODEL=qwen2.5:32b
WORKER_TEMPERATURE=0.7
WORKER_MAX_TOKENS=4000

# Alternative model combinations:
# Fast & economical:
#   ORCHESTRATOR_MODEL=llama3:8b
#   WORKER_MODEL=qwen2.5:14b
#
# Maximum quality:
#   ORCHESTRATOR_MODEL=qwen2.5:32b
#   WORKER_MODEL=qwen2.5:72b
#
# Same model (simpler, but less optimized):
#   ORCHESTRATOR_MODEL=qwen2.5:32b
#   WORKER_MODEL=qwen2.5:32b

# =============================================================================
# EMBEDDING MODEL
# =============================================================================

EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Alternative embedding models:
# - all-mpnet-base-v2 (768 dims, higher quality, slower)
# - all-MiniLM-L12-v2 (384 dims, balanced)
# - paraphrase-multilingual-MiniLM-L12-v2 (384 dims, multilingual)

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================

# Orchestrator Ollama
ORCHESTRATOR_OLLAMA_URL=http://orchestrator-ollama:11434
ORCHESTRATOR_OLLAMA_GPU=true
ORCHESTRATOR_OLLAMA_NUM_GPU=1
ORCHESTRATOR_OLLAMA_GPU_LAYERS=40

# Worker Ollama  
WORKER_OLLAMA_URL=http://worker-ollama:11434
WORKER_OLLAMA_GPU=true
WORKER_OLLAMA_NUM_GPU=1
WORKER_OLLAMA_GPU_LAYERS=40

# =============================================================================
# QDRANT (VECTOR DATABASE)
# =============================================================================

QDRANT_URL=http://qdrant:6333
QDRANT_API_KEY=
QDRANT_GRPC_PORT=6334
QDRANT_COLLECTION=documents
QDRANT_VECTOR_SIZE=384
QDRANT_DISTANCE_METRIC=Cosine  # Cosine, Euclid, or Dot

# =============================================================================
# API SERVICES
# =============================================================================

# Orchestrator API
ORCHESTRATOR_API_HOST=0.0.0.0
ORCHESTRATOR_API_PORT=8000
ORCHESTRATOR_API_WORKERS=4
ORCHESTRATOR_API_TIMEOUT=120

# Worker API
WORKER_API_HOST=0.0.0.0
WORKER_API_PORT=8001
WORKER_API_WORKERS=4
WORKER_API_TIMEOUT=120

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

FRONTEND_PORT=8080
STREAMING_ENABLED=true
SHOW_THINKING_PROCESS=true
THEME=auto  # light, dark, auto

# =============================================================================
# CRAWLER SETTINGS
# =============================================================================

# Crawl limits
MAX_PAGES_PER_DOMAIN=1000
CRAWL_DELAY_SECONDS=1
MAX_DEPTH=5
TIMEOUT_SECONDS=30
MAX_CONCURRENT_CRAWLS=10

# User agent
USER_AGENT=AI-RAG-Bot/1.0 (+https://github.com/yourusername/airag)

# Allowed file types (comma-separated)
ALLOWED_EXTENSIONS=html,htm,pdf,txt,md,doc,docx,csv

# Respect robots.txt
RESPECT_ROBOTS_TXT=true

# Authentication (for protected sites)
AUTH_ENABLED=false
AUTH_TYPE=none  # Options: none, basic, cas, saml, bearer

# =============================================================================
# WORKER BEHAVIOR
# =============================================================================

# RAG search settings
WORKER_TOP_K_RESULTS=8
WORKER_SIMILARITY_THRESHOLD=0.7
WORKER_CONTEXT_MAX_TOKENS=8000
WORKER_CHUNK_SIZE=512
WORKER_CHUNK_OVERLAP=50

# Structured lookup settings
FUZZY_MATCH_THRESHOLD=0.6
ENABLE_FALLBACK_SEARCH=true

# =============================================================================
# PERFORMANCE & OPTIMIZATION
# =============================================================================

# Concurrency
MAX_CONCURRENT_EMBEDDINGS=50
BATCH_SIZE=100
EMBEDDING_BATCH_SIZE=32

# Caching
ENABLE_RESPONSE_CACHE=true
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE_MB=1024

# Connection pooling
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20

# =============================================================================
# GPU CONFIGURATION
# =============================================================================

# GPU settings (for NVIDIA GPUs)
GPU_ENABLED=true
GPU_DEVICE_IDS=0  # Comma-separated for multiple GPUs: 0,1
GPU_MEMORY_FRACTION=0.9

# CUDA settings
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# =============================================================================
# LOGGING
# =============================================================================

LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json  # json or text
LOG_FILE=/var/log/airag/app.log
LOG_MAX_BYTES=10485760  # 10MB
LOG_BACKUP_COUNT=5

# Component-specific logging
ORCHESTRATOR_LOG_LEVEL=INFO
WORKER_LOG_LEVEL=INFO
CRAWLER_LOG_LEVEL=INFO

# =============================================================================
# SECURITY
# =============================================================================

# API authentication (optional)
API_KEY=
JWT_SECRET=change-me-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Rate limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD_SECONDS=60
RATE_LIMIT_STORAGE=memory  # memory or redis

# CORS settings
CORS_ENABLED=true
CORS_ORIGINS=*  # In production: http://localhost:8080,https://yourdomain.com
CORS_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_HEADERS=*

# =============================================================================
# STREAMING & WEBSOCKETS
# =============================================================================

# Server-Sent Events (SSE) configuration
SSE_ENABLED=true
SSE_KEEPALIVE_SECONDS=30
SSE_RETRY_MILLISECONDS=3000

# Thinking process streaming
STREAM_ORCHESTRATOR_THINKING=true
STREAM_WORKER_PROGRESS=true
STREAM_CHUNK_SIZE=64

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================

# Health checks
HEALTH_CHECK_INTERVAL_SECONDS=30
HEALTH_CHECK_TIMEOUT_SECONDS=10

# Metrics (Prometheus-compatible)
METRICS_ENABLED=false
METRICS_PORT=9090

# Tracing (OpenTelemetry)
TRACING_ENABLED=false
TRACING_ENDPOINT=http://jaeger:4318/v1/traces
TRACING_SERVICE_NAME=airag

# =============================================================================
# DATA PERSISTENCE
# =============================================================================

# Paths (relative to docker-compose.yml)
DATA_DIR=./data
CACHE_DIR=./data/cache
SECRETS_DIR=./secrets
MODELS_DIR=./data/models

# Database backup
AUTO_BACKUP_ENABLED=false
BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_DAYS=7

# =============================================================================
# ADVANCED SETTINGS
# =============================================================================

# Orchestrator advanced
ORCHESTRATOR_USE_CHAIN_OF_THOUGHT=false
ORCHESTRATOR_PARALLEL_VALIDATION=true
ORCHESTRATOR_MEMORY_ENABLED=false

# Worker advanced
WORKER_USE_RERANKING=false
WORKER_RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
WORKER_HYBRID_SEARCH=false  # Combine vector + keyword search

# Experimental features
ENABLE_GRAPHRAG=false  # Requires neo4j
ENABLE_MULTIMODAL=false  # Image/video understanding
ENABLE_SQL_BRIDGE=false  # Query structured databases

# =============================================================================
# DEBUGGING
# =============================================================================

DEBUG=false
VERBOSE_LOGGING=false
PROFILE_ENABLED=false
SAVE_INTERMEDIATE_RESULTS=false

# Development mode (disables caching, enables auto-reload)
DEV_MODE=false
AUTO_RELOAD=false

# =============================================================================
# ARM ARCHITECTURE SUPPORT
# =============================================================================
# Uncomment and adjust for ARM-based systems (e.g., Dell Pro Max with GB10)

# ARM_ARCHITECTURE=true
# OLLAMA_IMAGE=ollama/ollama:latest-arm64
# PYTHON_IMAGE=python:3.11-slim-arm64

# =============================================================================
# NOTES
# =============================================================================
# 
# GPU Memory Requirements:
# - Orchestrator (14B): ~9GB VRAM
# - Worker (32B): ~20GB VRAM
# - Total: ~30GB VRAM (fits on RTX 5090 with 32GB)
#
# For RTX 5090 with 32GB:
#   - Run both LLMs on same GPU (default config)
#   - Or split across 2 GPUs if available
#
# For systems with less VRAM:
#   - Use smaller models (7B/14B)
#   - Enable CPU offloading
#   - Use quantized models (Q4_K_M, Q5_K_M)
#
# Model download on first start:
#   - Orchestrator (14B): ~8GB download
#   - Worker (32B): ~19GB download
#   - Allow 10-15 minutes for first startup
#
